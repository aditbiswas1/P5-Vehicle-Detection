{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P5 - Vehicle Detection and Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I created a vehicle tracking pipeline using supervised learning algorithms on image related features from a vehicle dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from utils.imread_rgb import imread_rgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification\n",
    "\n",
    "The first step in solving the problem of identifying and tracking vehicles is to implement a binary classification algorithm which is capable of distinguishing between vehicles and non-vehicles. To implement this algorithm, i extracted gradient, color and spatial features from images and evaluated various standard classification algorithms from the sklearn toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicle_files = glob.glob('vehicles/*/*.png')\n",
    "non_vehicle_files = glob.glob('non-vehicles/*/*.png')\n",
    "vehicle_images = [imread_rgb(im) for im in vehicle_files]\n",
    "nonvehicle_images = [imread_rgb(im) for im in non_vehicle_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = np.vstack((vehicle_images, nonvehicle_images))\n",
    "del vehicle_images\n",
    "del nonvehicle_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.hstack((np.ones(len(vehicle_files)), np.zeros(len(non_vehicle_files))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Feature Selection\n",
    "There are multiple techniques to extract features from a given image. I decided to evaluate a handful of techniques by changing color space and various parameters of the feature extraction algorithms and comparing how well they train a linear SVM.\n",
    "To compare the quality of the features I evaluated the f1_score metric which is a weighted average or the precision, recall scores of the classification algorithm.\n",
    "\n",
    "#### 1.1.1 HOG features\n",
    "The Histogram of Gradient (HOG) is a feature descriptor found in traditional computer vision techniques. The technique counts occurences of gradient orientations in a localized portion of a given image, the main idea of the algorithm is that shapes of objects in an image can be described by these gradient orientations are thus considered useful. I used the ```skimage.feature.hog``` function to extract hog features from the images and determine which parameters seem to work best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from feature_extractors.hog_extractor import extract_hog_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color_space \t orient \t pix_per_cell \t channel \t f1_score\n"
     ]
    }
   ],
   "source": [
    "color_spaces = ['RGB','HSV', 'LUV', 'HLS', 'YUV', 'YCrCb']\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "channel = 'ALL'\n",
    "print('color_space \\t orient \\t pix_per_cell \\t channel \\t f1_score')\n",
    "for color_space in color_spaces:\n",
    "    X_train_features = []\n",
    "    X_test_features = []\n",
    "    for im in X_train:\n",
    "        X_train_features.append(extract_hog_features(im, cspace=color_space, orient=orient, \n",
    "        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "        hog_channel=channel))\n",
    "    for im in X_test:\n",
    "        X_test_features.append(extract_hog_features(im, cspace=color_space, orient=orient, \n",
    "        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "        hog_channel=channel))\n",
    "\n",
    "    X_train_features = np.asarray(X_train_features).astype(np.float64)\n",
    "    X_test_feature = np.asarray(X_test_features).astype(np.float64)\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X_train_features, y_train)\n",
    "    y_preds = clf.predict(X_test_features)\n",
    "    f1 = f1_score(y_test, y_preds)\n",
    "    print('{} \\t{} \\t{} \\t{} \\t{} : \\t{}'.format(color_space, orient,  pix_per_cell, cell_per_block, channel, f1))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_space = 'RGB'\n",
    "orients = [5,7,9,13,16]\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "channel = 'ALL'\n",
    "print('color_space \\t orient \\t pix_per_cell \\t channel \\t f1_score')\n",
    "for orient in orients:\n",
    "    X_train_features = []\n",
    "    X_test_features = []\n",
    "    for im in X_train:\n",
    "        X_train_features.append(extract_hog_features(im, cspace=color_space, orient=orient, \n",
    "        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "        hog_channel=channel))\n",
    "    for im in X_test:\n",
    "        X_test_features.append(extract_hog_features(im, cspace=color_space, orient=orient, \n",
    "        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "        hog_channel=channel))\n",
    "\n",
    "    X_train_features = np.asarray(X_train_features).astype(np.float64)\n",
    "    X_test_feature = np.asarray(X_test_features).astype(np.float64)\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(X_train_features, y_train)\n",
    "    y_preds = clf.predict(X_test_features)\n",
    "    f1 = f1_score(y_test, y_preds)\n",
    "    print('{} \\t{} \\t{} \\t{} \\t{} : \\t{}'.format(color_space, orient,  pix_per_cell, cell_per_block, channel, f1))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
